{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This file is part of Theano Geometry\n",
    "#\n",
    "# Copyright (C) 2017, Stefan Sommer (sommer@di.ku.dk)\n",
    "# https://bitbucket.org/stefansommer/theanogemetry\n",
    "#\n",
    "# Theano Geometry is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "#\n",
    "# Theano Geometry is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU General Public License for more details.\n",
    "#\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with Theano Geometry. If not, see <http://www.gnu.org/licenses/>.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Manifold Statistics - Examples on $\\mathbb{S}^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.manifolds.S2 import *\n",
    "M = S2(use_spherical_coords=True,chart_center='x')\n",
    "print(M)\n",
    "\n",
    "from src.plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riemannian structure\n",
    "from src.Riemannian import metric\n",
    "metric.initialize(M)\n",
    "\n",
    "# geodesics\n",
    "from src.Riemannian import geodesic\n",
    "geodesic.initialize(M)\n",
    "\n",
    "# Logarithm map\n",
    "from src.Riemannian import Log\n",
    "Log.initialize(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# coordinate form\n",
    "from src.stochastics import Brownian_coords\n",
    "Brownian_coords.initialize(M)\n",
    "\n",
    "N_samples = 256\n",
    "x = np.array([np.pi/2,np.pi/2])\n",
    "\n",
    "samples = np.zeros((N_samples,M.dim.eval()))\n",
    "for i in range(N_samples):\n",
    "    (ts,xs) = M.Brownian_coordsf(x,dWsf(M.dim.eval()))\n",
    "    samples[i] = xs[-1]\n",
    "\n",
    "# plot\n",
    "newfig()\n",
    "M.plot()\n",
    "for i in range(N_samples):\n",
    "    M.plotx(samples[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frechet mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.statistics.Frechet_mean import *\n",
    "\n",
    "res = Frechet_mean(M,lambda *args: M.Logf(*args), samples)\n",
    "Fm = res[0]\n",
    "print(\"loss = \", res[1])\n",
    "print(\"mean = \", Fm)\n",
    "iterations = res[2]\n",
    "\n",
    "newfig()\n",
    "M.plot(rotate = np.array([50,-45]))\n",
    "M.plotx(Fm)\n",
    "M.plotx(iterations)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tangent PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from src.statistics.tangent_PCA import *\n",
    "\n",
    "from src.utils import *\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = tangent_PCA(M,lambda *args: M.Logf(*args),x,samples)\n",
    "print(pca.get_covariance())\n",
    "\n",
    "plt.scatter(pca.transformed_Logs[:, 0], pca.transformed_Logs[:, 1])\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML mean estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {}\n",
    "options['samples_per_obs'] = 1\n",
    "options['epochs'] = 50\n",
    "options['learning_rate'] = .5e0\n",
    "options['varphi_update_rate'] = 1.\n",
    "options['initial'] = [np.array([0.,x[1]/8])]#[x+.5*np.random.randn(M.dim.eval())]\n",
    "options['verbose'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delyon/Hu guided process\n",
    "from src.stochastics.guided_process import *\n",
    "\n",
    "# guide function\n",
    "Cholesky = T.slinalg.Cholesky()\n",
    "# phi = lambda q,v: T.tensordot(T.nlinalg.MatrixInverse()(Cholesky(M.gsharp(q))),-(q-v).flatten(),(1,0))\n",
    "phi = lambda q,v: T.tensordot(Cholesky(M.g(q)).T,-(q-v).flatten(),(1,0))\n",
    "x0 = M.element()\n",
    "(Brownian_coords_guided,Brownian_coords_guidedf) = get_guided_likelihood(M,M.sde_Brownian_coords,phi,lambda x: Cholesky(M.gsharp(x)),x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition density\n",
    "# transition density etc.\n",
    "q0 = M.element()\n",
    "v = M.element()\n",
    "thetas = (q0,)\n",
    "log_p_Tf = theano.function([q0,v],log_p_T(q0,v,dWs(M.dim),Brownian_coords_guided,phi,options,sde=M.sde_Brownian_coords))\n",
    "dlog_p_Tf = theano.function([q0,v],dlog_p_T(thetas,q0,v,dWs(M.dim),Brownian_coords_guided,phi,options,sde=M.sde_Brownian_coords))\n",
    "p_Tf = theano.function([q0,v],T.exp(log_p_T(q0,v,dWs(M.dim),Brownian_coords_guided,phi,options,sde=M.sde_Brownian_coords)))\n",
    "\n",
    "v = x\n",
    "%time print(log_p_Tf(x,v))\n",
    "%time print(p_Tf(x,v))\n",
    "%time print(dlog_p_Tf(x,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.statistics.mle import *\n",
    "\n",
    "def llog_p_T(thetas,pars):\n",
    "    (v,seed) = pars\n",
    "    if seed:\n",
    "        srng.seed(seed)\n",
    "    q = thetas[0]\n",
    "    return dlog_p_Tf(q,v)\n",
    "\n",
    "def update_thetas(thetas, dthetas):\n",
    "    q = thetas[0]\n",
    "    \n",
    "    q += options['learning_rate']*np.dot(M.gsharpf(q),dthetas[0]) # use Riemannian g-gradient\n",
    "    \n",
    "    return (q,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run MLE\n",
    "(thetas, log_likelihood, log_likelihoods, thetass) = iterative_mle(samples,llog_p_T,update_thetas,options)\n",
    "\n",
    "# plot\n",
    "plt.plot(range(options['epochs']),log_likelihoods)\n",
    "# plt.savefig('ML_likelihoods.pdf')\n",
    "plt.show()\n",
    "plt.plot(range(options['epochs']),thetass[0].reshape((thetass[0].shape[0],-1)))\n",
    "# plt.savefig('ML_thetas.pdf')\n",
    "plt.show()\n",
    "\n",
    "M.newfig()\n",
    "M.plot()\n",
    "M.plotx(thetas[0],s=150)\n",
    "M.plotx(np.vstack((options['initial'][0],thetass[0])),color='blue',linewidth=2.5)\n",
    "M.plotx(Fm,s=150,color='red')\n",
    "M.plotx(np.vstack((np.zeros((1,2)),iterations)),color='red',linewidth=2.5)\n",
    "plt.savefig('MLmean_iterations.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-sample test (Huilling Le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic development\n",
    "from src.stochastics import Brownian_coords\n",
    "Brownian_coords.initialize(M)\n",
    "\n",
    "from src.framebundle import FM\n",
    "FM.initialize(M)\n",
    "from src.stochastics import stochastic_development\n",
    "stochastic_development.initialize(M)\n",
    "from src.stochastics import Brownian_development\n",
    "Brownian_development.initialize(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_samples = 100\n",
    "\n",
    "# Mean of sample distributions\n",
    "x = np.array([np.pi/2+0.5,np.pi/2+0.5])\n",
    "y = np.array([np.pi/2-0.5,np.pi/2-0.5])\n",
    "\n",
    "# chart point:\n",
    "p = np.array([np.pi/2,np.pi/2])\n",
    "\n",
    "x_sample = np.zeros((N_samples,M.dim.eval()))\n",
    "y_sample = np.zeros((N_samples,M.dim.eval()))\n",
    "for i in range(N_samples):\n",
    "    (tsx,xs) = M.Brownian_developmentf(x,0.1*dWsf(M.dim.eval()))\n",
    "    x_sample[i] = xs[-1]\n",
    "    (tsy,ys) = M.Brownian_developmentf(y,0.1*dWsf(M.dim.eval()))\n",
    "    y_sample[i] = ys[-1]\n",
    "\n",
    "# plot\n",
    "%matplotlib inline\n",
    "newfig()\n",
    "M.plot()\n",
    "for i in range(N_samples):\n",
    "    M.plotx(x_sample[i], color = 'b')\n",
    "    M.plotx(y_sample[i], color = 'r')\n",
    "    M.plotx(p, color = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two sample test:\n",
    "def h(x,y,p_chart):\n",
    "    # x, y tangent vectors\n",
    "    qx = M.Expf(p_chart,x)\n",
    "    qy = M.Expf(p_chart,y)\n",
    "    \n",
    "    return np.linalg.norm(M.Logf(qx,qy)[0])**2\n",
    "\n",
    "def D_vexppv(p,v):\n",
    "    # x,y tangent vectors\n",
    "    return T.jacobian(M.Exp(p,v),v)\n",
    "\n",
    "p = T.vector()\n",
    "v = T.vector()\n",
    "hesshf = theano.function([p,v], D_vexppv(p,v), on_unused_input='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = np.array([np.pi/2,np.pi/2])\n",
    "x0 = np.array([1.,1.])\n",
    "y0 = np.array([0.5,0.5])\n",
    "print(hesshf(p0,y0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.statistics.Frechet_mean import *\n",
    "\n",
    "# Frechet mean of X\n",
    "resx = Frechet_mean(M,lambda *args: M.Logf(*args), x_sample)\n",
    "Fmx = resx[0]\n",
    "print(\"loss = \", resx[1])\n",
    "print(\"mean = \", Fmx)\n",
    "iterationsx = resx[2]\n",
    "\n",
    "# Frechet mean of Y\n",
    "resy = Frechet_mean(M,lambda *args: M.Logf(*args), y_sample)\n",
    "Fmy = resy[0]\n",
    "print(\"loss = \", resy[1])\n",
    "print(\"mean = \", Fmy)\n",
    "iterationsy = resy[2]\n",
    "\n",
    "newfig()\n",
    "M.plot()#rotate = np.array([50,-45]))\n",
    "M.plotx(Fmx)\n",
    "M.plotx(iterationsx)\n",
    "M.plotx(Fmy)\n",
    "M.plotx(iterationsy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logx = np.zeros((N_samples,M.dim.eval()))\n",
    "Logy = np.zeros((N_samples,M.dim.eval()))\n",
    "for i in range(N_samples):\n",
    "    Logx = M.Logf(p,x_sample[i])[0]\n",
    "    Logy = M.Logf(p,y_sample[i])[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
